{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/marcosrodrigo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marcosrodrigo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/marcosrodrigo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/marcosrodrigo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# Punkt permite separar un texto en frases.\n",
    "nltk.download('punkt')\n",
    "# Descarga todas las palabras vacias, es decir, aquellas que no aportan nada al significado del texto\n",
    "nltk.download('stopwords')\n",
    "#Paquete WordNetLemmatizer, este es usado para encontrar el lema de cada palabr\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-profiling in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (3.2.0)\n",
      "Collecting joblib~=1.1.0 (from pandas-profiling)\n",
      "  Using cached joblib-1.1.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (1.13.1)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (2.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (3.9.2)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (6.0.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.1.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (2.1.3)\n",
      "Requirement already satisfied: visions==0.7.4 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (1.26.4)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: missingno>=0.4.2 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (0.5.2)\n",
      "Requirement already satisfied: phik>=0.11.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (0.12.4)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (4.66.5)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (0.13.2)\n",
      "Requirement already satisfied: multimethod>=1.4 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas-profiling) (2.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (3.3)\n",
      "Requirement already satisfied: imagehash in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (4.3.2)\n",
      "Requirement already satisfied: Pillow in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.2.0->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.2.0->pandas-profiling) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.2.0->pandas-profiling) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.2.0->pandas-profiling) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.2.0->pandas-profiling) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pydantic>=1.8.1->pandas-profiling) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pydantic>=1.8.1->pandas-profiling) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pydantic>=1.8.1->pandas-profiling) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.24.0->pandas-profiling) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.24.0->pandas-profiling) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.24.0->pandas-profiling) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.24.0->pandas-profiling) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling) (1.7.0)\n",
      "Using cached joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "Installing collected packages: joblib\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-learn 1.5.1 requires joblib>=1.2.0, but you have joblib 1.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.1.1\n",
      "Requirement already satisfied: vaderSentiment in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from requests->vaderSentiment) (2024.12.14)\n",
      "Requirement already satisfied: seaborn in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Collecting joblib>=1.1.1 (from imbalanced-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.4.2\n",
      "Requirement already satisfied: nltk in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: scipy in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/marcosrodrigo/opt/anaconda3/lib/python3.12/site-packages (from scipy) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/marcosrodrigo/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "\n",
    "!{sys.executable} -m pip install pandas-profiling\n",
    "!pip install vaderSentiment\n",
    "!pip install seaborn\n",
    "!pip install imbalanced-learn\n",
    "!pip install nltk\n",
    "!pip install scipy\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import nltk\n",
    "nltk.data.path.append(\"C:/Users/Felipe Jaimes/nltk_data\")\n",
    "nltk.download('punkt', force=True)\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats as st\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Perfilamiento, entendimiento de los datos y  análisis de la calidad de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cargada=pd.read_csv('Data/fake_news_spanish.csv', sep=';', encoding = 'utf-8')\n",
    "# Asignación a una nueva variable de los datos leidos\n",
    "data=data_cargada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>02/06/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>01/10/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>25/04/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>03/01/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>09/03/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El PNV consolida su mayoría, el PSE salva los ...</td>\n",
       "      <td>Los nacionalistas consiguen las alcaldías de B...</td>\n",
       "      <td>26/05/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>El exconsejero Núria Marín pide el indulto en ...</td>\n",
       "      <td>Sus familiares aluden a su honestidad e integr...</td>\n",
       "      <td>16/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>La Fiscalía pide prisión incondicional para lo...</td>\n",
       "      <td>Suprime el delito de rebelión que les imputó i...</td>\n",
       "      <td>26/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>José Manuel Pérez Tornero, el creador de la te...</td>\n",
       "      <td>El futuro presidente de RTVE es licenciado en ...</td>\n",
       "      <td>25/02/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>La 'Ayusización' del BNG: Santiago Abascal ins...</td>\n",
       "      <td>Pablo Santiago Abascal planea vivir de las ren...</td>\n",
       "      <td>10/05/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Label                                             Titulo  \\\n",
       "0  ID      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1  ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3  ID      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4  ID      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "5  ID      1  El PNV consolida su mayoría, el PSE salva los ...   \n",
       "6  ID      0  El exconsejero Núria Marín pide el indulto en ...   \n",
       "7  ID      1  La Fiscalía pide prisión incondicional para lo...   \n",
       "8  ID      1  José Manuel Pérez Tornero, el creador de la te...   \n",
       "9  ID      0  La 'Ayusización' del BNG: Santiago Abascal ins...   \n",
       "\n",
       "                                         Descripcion       Fecha  \n",
       "0  El diario británico publicó este pasado jueves...  02/06/2023  \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...  01/10/2023  \n",
       "2  El valencianismo convoca en Castelló su fiesta...  25/04/2022  \n",
       "3  En política, igual que hay que negociar con lo...  03/01/2022  \n",
       "4  En una entrevista en El Punt Avui, el líder de...  09/03/2018  \n",
       "5  Los nacionalistas consiguen las alcaldías de B...  26/05/2019  \n",
       "6  Sus familiares aluden a su honestidad e integr...  16/09/2022  \n",
       "7  Suprime el delito de rebelión que les imputó i...  26/09/2019  \n",
       "8  El futuro presidente de RTVE es licenciado en ...  25/02/2021  \n",
       "9  Pablo Santiago Abascal planea vivir de las ren...  10/05/2021  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57063 entries, 0 to 57062\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           57063 non-null  object\n",
      " 1   Label        57063 non-null  int64 \n",
      " 2   Titulo       57047 non-null  object\n",
      " 3   Descripcion  57063 non-null  object\n",
      " 4   Fecha        57063 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57063, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicializacion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marcosrodrigo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "nltk.download('stopwords')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Conteo_Titulo</th>\n",
       "      <th>Conteo_Descripcion</th>\n",
       "      <th>Max_Titulo</th>\n",
       "      <th>Min_Descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>02/06/2023</td>\n",
       "      <td>77</td>\n",
       "      <td>218</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>01/10/2023</td>\n",
       "      <td>104</td>\n",
       "      <td>3251</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>25/04/2022</td>\n",
       "      <td>77</td>\n",
       "      <td>169</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>110</td>\n",
       "      <td>133</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>09/03/2018</td>\n",
       "      <td>72</td>\n",
       "      <td>242</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57058</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El Defensor del Pueblo reclama a la Comunidad ...</td>\n",
       "      <td>El gobierno regional han indicado que la atenc...</td>\n",
       "      <td>08/06/2021</td>\n",
       "      <td>116</td>\n",
       "      <td>244</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57059</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>El EQUO plantea ceder la presidencia de la Com...</td>\n",
       "      <td>Si la higiene democrática nos lleva a esa exig...</td>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>100</td>\n",
       "      <td>314</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57060</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Alberto Garzón: 'Que los Borbones son unos lad...</td>\n",
       "      <td>El coordinador federal de IU asegura que la mo...</td>\n",
       "      <td>12/07/2018</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57061</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Vox exige entrar en el Gobierno de Castilla y ...</td>\n",
       "      <td>Santiago Abascal: Vox tiene el derecho y el de...</td>\n",
       "      <td>13/02/2022</td>\n",
       "      <td>118</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57062</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Unas 300 personas protestan contra la visita d...</td>\n",
       "      <td>Los Mossos dEsquadra han blindado los alrededo...</td>\n",
       "      <td>09/10/2020</td>\n",
       "      <td>64</td>\n",
       "      <td>193</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57063 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label                                             Titulo  \\\n",
       "0      ID      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1      ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2      ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3      ID      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4      ID      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "...    ..    ...                                                ...   \n",
       "57058  ID      1  El Defensor del Pueblo reclama a la Comunidad ...   \n",
       "57059  ID      0  El EQUO plantea ceder la presidencia de la Com...   \n",
       "57060  ID      1  Alberto Garzón: 'Que los Borbones son unos lad...   \n",
       "57061  ID      1  Vox exige entrar en el Gobierno de Castilla y ...   \n",
       "57062  ID      1  Unas 300 personas protestan contra la visita d...   \n",
       "\n",
       "                                             Descripcion       Fecha  \\\n",
       "0      El diario británico publicó este pasado jueves...  02/06/2023   \n",
       "1      REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...  01/10/2023   \n",
       "2      El valencianismo convoca en Castelló su fiesta...  25/04/2022   \n",
       "3      En política, igual que hay que negociar con lo...  03/01/2022   \n",
       "4      En una entrevista en El Punt Avui, el líder de...  09/03/2018   \n",
       "...                                                  ...         ...   \n",
       "57058  El gobierno regional han indicado que la atenc...  08/06/2021   \n",
       "57059  Si la higiene democrática nos lleva a esa exig...  08/09/2020   \n",
       "57060  El coordinador federal de IU asegura que la mo...  12/07/2018   \n",
       "57061  Santiago Abascal: Vox tiene el derecho y el de...  13/02/2022   \n",
       "57062  Los Mossos dEsquadra han blindado los alrededo...  09/10/2020   \n",
       "\n",
       "       Conteo_Titulo  Conteo_Descripcion  Max_Titulo  Min_Descripcion  \n",
       "0                 77                 218           9                1  \n",
       "1                104                3251          10                1  \n",
       "2                 77                 169          10                2  \n",
       "3                110                 133          12                2  \n",
       "4                 72                 242          11                1  \n",
       "...              ...                 ...         ...              ...  \n",
       "57058            116                 244           9                1  \n",
       "57059            100                 314          11                1  \n",
       "57060             90                  70          14                2  \n",
       "57061            118                 232          16                1  \n",
       "57062             64                 193           9                1  \n",
       "\n",
       "[57063 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "textos_analisis = data.copy()\n",
    "textos_analisis['Conteo_Titulo'] = [len(str(x)) for x in textos_analisis['Titulo']]\n",
    "textos_analisis['Conteo_Descripcion'] = [len(str(x)) for x in textos_analisis['Descripcion']]\n",
    "\n",
    "textos_analisis['Max_Titulo'] = [[max([len(str(x)) for x in str(i).split(' ')])][0] for i in textos_analisis['Titulo']]\n",
    "textos_analisis['Max_Titulo'] = [[max([len(str(x)) for x in str(i).split(' ')])][0] for i in textos_analisis['Titulo']]\n",
    "textos_analisis['Min_Descripcion'] = [[min([len(str(x)) for x in str(i).split(' ')])][0] for i in textos_analisis['Descripcion']]\n",
    "textos_analisis['Min_Descripcion'] = [[min([len(str(x)) for x in str(i).split(' ')])][0] for i in textos_analisis['Descripcion']]\n",
    "\n",
    "textos_analisis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de datos y toquenización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             object\n",
       "Label           int64\n",
       "Titulo         object\n",
       "Descripcion    object\n",
       "Fecha          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que hay datos que no se encuentran en tipo String los convertirimos a String y la Fecha tambien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Titulo'] = data['Titulo'].astype('string')\n",
    "data['Descripcion'] = data['Descripcion'].astype('string')\n",
    "\n",
    "data['Fecha'] = pd.to_datetime(data['Fecha'], format='%d/%m/%Y')\n",
    "df=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a buscar los datos Nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Label           0\n",
       "Titulo         16\n",
       "Descripcion     0\n",
       "Fecha           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos que pasa en la columna titulo ya que es la unica fila que tiene titulos vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Hace unos 75 años, Hermann Göring testificó en...</td>\n",
       "      <td>2019-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Evidentemente, Barak Obama ha sido arrestado e...</td>\n",
       "      <td>2022-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>\"Después de convertirme en presidente, le pedí...</td>\n",
       "      <td>2022-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Me pasaron de buena fuente hoy (un vecino del ...</td>\n",
       "      <td>2023-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7345</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Defienden dichos con capitulos de Don Gato.\n",
       "\n",
       "C...</td>\n",
       "      <td>2023-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7652</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Lean (y vean la imagen) con mucha atención:\n",
       "\n",
       "S...</td>\n",
       "      <td>2018-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>¿Sabías que Francisco Sagasti salió a marchar ...</td>\n",
       "      <td>2018-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15159</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Declarar a Bill Gates enemigo público y proces...</td>\n",
       "      <td>2024-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19415</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Con el fin de captar votos están dispuestos a ...</td>\n",
       "      <td>2017-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24806</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>CUANDO LAS IMÁGENES HABLAN MÁS QUE PALABRAS.\n",
       "\n",
       "...</td>\n",
       "      <td>2018-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35816</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>#ÚLTIMA_HORA Le ordenaré a los empresarios de ...</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36724</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Como muchos de ustedes recordarán, ayer por la...</td>\n",
       "      <td>2023-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40295</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Juanma Moreno Bonilla, presidente de la Junta ...</td>\n",
       "      <td>2020-08-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41810</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>¡¡ESTA LA PURA VERDAD!!\n",
       "\n",
       "¡¡NO ES NECESARIO VER...</td>\n",
       "      <td>2017-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47967</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Se han dado a conocer los datos electorales pr...</td>\n",
       "      <td>2019-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55146</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Denuncia Pública\n",
       "Se veía venir... En Gualaceo\n",
       "...</td>\n",
       "      <td>2023-02-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label Titulo                                        Descripcion  \\\n",
       "3243   ID      0   <NA>  Hace unos 75 años, Hermann Göring testificó en...   \n",
       "4189   ID      0   <NA>  Evidentemente, Barak Obama ha sido arrestado e...   \n",
       "5041   ID      0   <NA>  \"Después de convertirme en presidente, le pedí...   \n",
       "5644   ID      0   <NA>  Me pasaron de buena fuente hoy (un vecino del ...   \n",
       "7345   ID      0   <NA>  Defienden dichos con capitulos de Don Gato.\n",
       "\n",
       "C...   \n",
       "7652   ID      0   <NA>  Lean (y vean la imagen) con mucha atención:\n",
       "\n",
       "S...   \n",
       "9700   ID      0   <NA>  ¿Sabías que Francisco Sagasti salió a marchar ...   \n",
       "15159  ID      0   <NA>  Declarar a Bill Gates enemigo público y proces...   \n",
       "19415  ID      0   <NA>  Con el fin de captar votos están dispuestos a ...   \n",
       "24806  ID      0   <NA>  CUANDO LAS IMÁGENES HABLAN MÁS QUE PALABRAS.\n",
       "\n",
       "...   \n",
       "35816  ID      0   <NA>  #ÚLTIMA_HORA Le ordenaré a los empresarios de ...   \n",
       "36724  ID      0   <NA>  Como muchos de ustedes recordarán, ayer por la...   \n",
       "40295  ID      0   <NA>  Juanma Moreno Bonilla, presidente de la Junta ...   \n",
       "41810  ID      0   <NA>  ¡¡ESTA LA PURA VERDAD!!\n",
       "\n",
       "¡¡NO ES NECESARIO VER...   \n",
       "47967  ID      0   <NA>  Se han dado a conocer los datos electorales pr...   \n",
       "55146  ID      0   <NA>  Denuncia Pública\n",
       "Se veía venir... En Gualaceo\n",
       "...   \n",
       "\n",
       "           Fecha  \n",
       "3243  2019-06-16  \n",
       "4189  2022-03-10  \n",
       "5041  2022-03-16  \n",
       "5644  2023-04-08  \n",
       "7345  2023-07-02  \n",
       "7652  2018-08-04  \n",
       "9700  2018-12-26  \n",
       "15159 2024-08-02  \n",
       "19415 2017-10-28  \n",
       "24806 2018-06-28  \n",
       "35816 2021-05-07  \n",
       "36724 2023-02-04  \n",
       "40295 2020-08-21  \n",
       "41810 2017-10-19  \n",
       "47967 2019-04-19  \n",
       "55146 2023-02-15  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este haremos que los titulos que estan vacios seran remplazados con las primeras palabras de la descripcion para no eliminar estos datos del set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con Título nulo antes: 16\n",
      "Filas con Título nulo después: 0\n"
     ]
    }
   ],
   "source": [
    "def imputar_titulo_desde_descripcion(titulo, descripcion, max_palabras=5):\n",
    "    if pd.isna(titulo):  \n",
    "        if isinstance(descripcion, str):  \n",
    "            palabras = descripcion.split()  \n",
    "            return ' '.join(palabras[:max_palabras])  \n",
    "        return ''  \n",
    "    return titulo  \n",
    "\n",
    "print(f\"Filas con Título nulo antes: {df['Titulo'].isna().sum()}\")\n",
    "df['Titulo'] = df.apply(lambda row: imputar_titulo_desde_descripcion(row['Titulo'], row['Descripcion']), axis=1)\n",
    "print(f\"Filas con Título nulo después: {df['Titulo'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos a revisar si hay datos duplicados en el Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay esta cantidad de datos duplicados:  445\n"
     ]
    }
   ],
   "source": [
    "duplicados = df[df.duplicated(keep='first')]\n",
    "print(\"Hay esta cantidad de datos duplicados: \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>La investigación policial por los balazos a un...</td>\n",
       "      <td>Las pesquisas internas de la Policía no han si...</td>\n",
       "      <td>2021-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El Constitucional avala la condena por sedició...</td>\n",
       "      <td>El pleno del tribunal rechaza el recurso prese...</td>\n",
       "      <td>2021-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Escándalo de corrupción salpica a líderes sind...</td>\n",
       "      <td>Un escándalo de corrupción ha salpicado a líde...</td>\n",
       "      <td>2023-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Más Madrid con Mónica García se proyecta hacia...</td>\n",
       "      <td>Las últimas encuestas sitúan al partido como t...</td>\n",
       "      <td>2021-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>La Fiscalía vincula al emérito con las cuentas...</td>\n",
       "      <td>Según las pesquisas del Ministerio Público, lo...</td>\n",
       "      <td>2021-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56698</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Un periodista refugiado palestino denuncia un ...</td>\n",
       "      <td>Muath Hamed, refugiado en España junto a su fa...</td>\n",
       "      <td>2021-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56766</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Los técnicos municipales que denunciaron anoma...</td>\n",
       "      <td>Los dos empleados del organismo municipal Info...</td>\n",
       "      <td>2021-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56931</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>La extrema derecha busca sacar rédito político...</td>\n",
       "      <td>La vicepresidenta valenciana presenta este mié...</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56962</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Proponen convertir el pazo de Meirás en un cen...</td>\n",
       "      <td>La propuesta ha sido firmada por casi 1.600 pe...</td>\n",
       "      <td>2021-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57018</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El Supremo confirma la condena a un padre por ...</td>\n",
       "      <td>El Alto Tribunal desestima el recurso del padr...</td>\n",
       "      <td>2021-04-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label                                             Titulo  \\\n",
       "2820   ID      1  La investigación policial por los balazos a un...   \n",
       "2865   ID      1  El Constitucional avala la condena por sedició...   \n",
       "2981   ID      0  Escándalo de corrupción salpica a líderes sind...   \n",
       "3335   ID      1  Más Madrid con Mónica García se proyecta hacia...   \n",
       "3473   ID      1  La Fiscalía vincula al emérito con las cuentas...   \n",
       "...    ..    ...                                                ...   \n",
       "56698  ID      1  Un periodista refugiado palestino denuncia un ...   \n",
       "56766  ID      1  Los técnicos municipales que denunciaron anoma...   \n",
       "56931  ID      1  La extrema derecha busca sacar rédito político...   \n",
       "56962  ID      1  Proponen convertir el pazo de Meirás en un cen...   \n",
       "57018  ID      1  El Supremo confirma la condena a un padre por ...   \n",
       "\n",
       "                                             Descripcion      Fecha  \n",
       "2820   Las pesquisas internas de la Policía no han si... 2021-04-24  \n",
       "2865   El pleno del tribunal rechaza el recurso prese... 2021-04-22  \n",
       "2981   Un escándalo de corrupción ha salpicado a líde... 2023-05-06  \n",
       "3335   Las últimas encuestas sitúan al partido como t... 2021-04-17  \n",
       "3473   Según las pesquisas del Ministerio Público, lo... 2021-04-26  \n",
       "...                                                  ...        ...  \n",
       "56698  Muath Hamed, refugiado en España junto a su fa... 2021-04-09  \n",
       "56766  Los dos empleados del organismo municipal Info... 2021-04-13  \n",
       "56931  La vicepresidenta valenciana presenta este mié... 2021-04-20  \n",
       "56962  La propuesta ha sido firmada por casi 1.600 pe... 2021-04-28  \n",
       "57018  El Alto Tribunal desestima el recurso del padr... 2021-04-26  \n",
       "\n",
       "[445 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.duplicated()]\n",
    "# df = df.drop_duplicates()\n",
    "# df = df.drop_duplicates(subset=['Titulo', 'Descripcion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas totales en df: 56613\n",
      "Filas con Título nulo antes: 0\n",
      "Filas con Label nulo: 0\n",
      "Filas con Descripción nula: 0\n"
     ]
    }
   ],
   "source": [
    "#ELIMINAR\n",
    "print(f\"Filas totales en df: {len(df)}\")\n",
    "print(f\"Filas con Título nulo antes: {df['Titulo'].isna().sum()}\")\n",
    "print(f\"Filas con Label nulo: {df['Label'].isna().sum()}\")\n",
    "print(f\"Filas con Descripción nula: {df['Descripcion'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendremos un Set de palabras sospechasas que consideramos que si el texto del titulo o descripccion contiene estas podria ser catalogado como  mas propenso a ser falso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_sospechosas = set([\n",
    "    'secreto', 'impactante', 'milagrosa', 'urgente', 'impresionante', 'sorprendente', 'insólito',\n",
    "    'descubierto', 'alerta', 'indignante', 'peligroso', 'exclusivo', 'aterrador', 'impresionante',\n",
    "    'conspiración', 'oculto', 'prohibido', 'mentira', 'falso', 'desmentido', 'engaño',\n",
    "    'corrupción', 'censurado', 'revelación', 'encubierto', 'manipulación', 'trampa',\n",
    "    'milagro', 'cura', 'prohibida', 'veneno', 'dañino', 'tóxico', 'ilegal', 'secreto',\n",
    "    'remedio', 'increíble', 'fantástico', 'desconocido', 'nunca visto', 'no quieren que sepas',\n",
    "    'última hora', 'no creerás', 'nadie lo esperaba', 'urgente', 'alerta máxima', 'devastador',\n",
    "    'infalible', 'descubre', 'inexplicable', 'definitivo', 'drástico', 'imperdible', 'viral',\n",
    "    'terror', 'amenaza', 'pánico', 'apocalipsis', 'devastador', 'tragedia', 'colapso',\n",
    "    'desastre', 'crisis', 'fracaso', 'fin del mundo', 'poderoso', 'letal', 'brutal',\n",
    "    'gana dinero', 'secreto bancario', 'hack', 'truco', 'fórmula mágica', 'sistema infalible',\n",
    "    'multiplica tu dinero', 'solución definitiva', 'inversión garantizada', 'fácil y rápido',\n",
    "    'químico peligroso', 'cura definitiva', 'anticancerígeno', 'natural y seguro', 'sin efectos secundarios',\n",
    "    'poder de la mente', 'médicos lo odian', 'ciencia lo confirma', 'demostrado',\n",
    "    'impresionante', 'alucinante', 'no lo podrás creer', 'revolucionario', 'radical', 'inigualable',\n",
    "    'impactante', 'sorprendente', 'irrepetible', 'shock', 'devastador', 'asombroso'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca lo que haremos es normalizar los caracteres unicode y remover los acentos. Ademas de esto volvemos el texto a minusculas, tokenizamos las palabras, eliminamos signos de puntuacion y se aplica la lematizacion para poder reducir sus palabras a su forma base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')    \n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [re.sub(r'[^\\w\\s]', '', word) for word in tokens if word.isalnum()]    \n",
    "    tokens = [p.number_to_words(word) if word.isdigit() else word for word in tokens]\n",
    "    # tokens = [word for word in tokens if word not in stop_words]\n",
    "    # tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/623137465.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Titulo_procesado'] = df['Titulo'].apply(lambda x: preprocess_text(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/623137465.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Descripcion_procesado'] = df['Descripcion'].apply(lambda x: preprocess_text(x))\n"
     ]
    }
   ],
   "source": [
    "df['Titulo_procesado'] = df['Titulo'].apply(lambda x: preprocess_text(x))\n",
    "df['Descripcion_procesado'] = df['Descripcion'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Titulo_procesado</th>\n",
       "      <th>Descripcion_procesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>guardian va con sanchez necesita que su apuest...</td>\n",
       "      <td>el diario britanico publico este pasado jueves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>revelan que el gobierno negocio la liberacion ...</td>\n",
       "      <td>revelan que el gobierno negocio la liberacion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>el o nunca de joan fuster sobre el estatuto va...</td>\n",
       "      <td>el valencianismo convoca en castello su fiesta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>iglesias alienta a yolanda diaz erc y eh bildu...</td>\n",
       "      <td>en politica igual que hay que negociar con los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>puigdemont seria ninguna tragedia una repetici...</td>\n",
       "      <td>en una entrevista en el punt avui el lider de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57058</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El Defensor del Pueblo reclama a la Comunidad ...</td>\n",
       "      <td>El gobierno regional han indicado que la atenc...</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>el defensor del pueblo reclama a la comunidad ...</td>\n",
       "      <td>el gobierno regional han indicado que la atenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57059</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>El EQUO plantea ceder la presidencia de la Com...</td>\n",
       "      <td>Si la higiene democrática nos lleva a esa exig...</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>el equo plantea ceder la presidencia de la com...</td>\n",
       "      <td>si la higiene democratica nos lleva a esa exig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57060</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Alberto Garzón: 'Que los Borbones son unos lad...</td>\n",
       "      <td>El coordinador federal de IU asegura que la mo...</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>alberto garzon los borbones son unos ladrones ...</td>\n",
       "      <td>el coordinador federal de iu asegura que la mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57061</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Vox exige entrar en el Gobierno de Castilla y ...</td>\n",
       "      <td>Santiago Abascal: Vox tiene el derecho y el de...</td>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>vox exige entrar en el gobierno de castilla y ...</td>\n",
       "      <td>santiago abascal vox tiene el derecho y el deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57062</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Unas 300 personas protestan contra la visita d...</td>\n",
       "      <td>Los Mossos dEsquadra han blindado los alrededo...</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>unas three hundred personas protestan contra l...</td>\n",
       "      <td>los mossos desquadra han blindado los alrededo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56613 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label                                             Titulo  \\\n",
       "0      ID      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1      ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2      ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3      ID      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4      ID      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "...    ..    ...                                                ...   \n",
       "57058  ID      1  El Defensor del Pueblo reclama a la Comunidad ...   \n",
       "57059  ID      0  El EQUO plantea ceder la presidencia de la Com...   \n",
       "57060  ID      1  Alberto Garzón: 'Que los Borbones son unos lad...   \n",
       "57061  ID      1  Vox exige entrar en el Gobierno de Castilla y ...   \n",
       "57062  ID      1  Unas 300 personas protestan contra la visita d...   \n",
       "\n",
       "                                             Descripcion      Fecha  \\\n",
       "0      El diario británico publicó este pasado jueves... 2023-06-02   \n",
       "1      REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ... 2023-10-01   \n",
       "2      El valencianismo convoca en Castelló su fiesta... 2022-04-25   \n",
       "3      En política, igual que hay que negociar con lo... 2022-01-03   \n",
       "4      En una entrevista en El Punt Avui, el líder de... 2018-03-09   \n",
       "...                                                  ...        ...   \n",
       "57058  El gobierno regional han indicado que la atenc... 2021-06-08   \n",
       "57059  Si la higiene democrática nos lleva a esa exig... 2020-09-08   \n",
       "57060  El coordinador federal de IU asegura que la mo... 2018-07-12   \n",
       "57061  Santiago Abascal: Vox tiene el derecho y el de... 2022-02-13   \n",
       "57062  Los Mossos dEsquadra han blindado los alrededo... 2020-10-09   \n",
       "\n",
       "                                        Titulo_procesado  \\\n",
       "0      guardian va con sanchez necesita que su apuest...   \n",
       "1      revelan que el gobierno negocio la liberacion ...   \n",
       "2      el o nunca de joan fuster sobre el estatuto va...   \n",
       "3      iglesias alienta a yolanda diaz erc y eh bildu...   \n",
       "4      puigdemont seria ninguna tragedia una repetici...   \n",
       "...                                                  ...   \n",
       "57058  el defensor del pueblo reclama a la comunidad ...   \n",
       "57059  el equo plantea ceder la presidencia de la com...   \n",
       "57060  alberto garzon los borbones son unos ladrones ...   \n",
       "57061  vox exige entrar en el gobierno de castilla y ...   \n",
       "57062  unas three hundred personas protestan contra l...   \n",
       "\n",
       "                                   Descripcion_procesado  \n",
       "0      el diario britanico publico este pasado jueves...  \n",
       "1      revelan que el gobierno negocio la liberacion ...  \n",
       "2      el valencianismo convoca en castello su fiesta...  \n",
       "3      en politica igual que hay que negociar con los...  \n",
       "4      en una entrevista en el punt avui el lider de ...  \n",
       "...                                                  ...  \n",
       "57058  el gobierno regional han indicado que la atenc...  \n",
       "57059  si la higiene democratica nos lleva a esa exig...  \n",
       "57060  el coordinador federal de iu asegura que la mo...  \n",
       "57061  santiago abascal vox tiene el derecho y el deb...  \n",
       "57062  los mossos desquadra han blindado los alrededo...  \n",
       "\n",
       "[56613 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procesaremos el texto para extraer características específicas de este. Contamos el número total de palabras después de tokenizar el texto, identifica cuántas palabras sospechosas aparecen, calcula el sentimiento general del texto usando un analizador de polaridad, y cuenta los signos de exclamación. La función utiliza lematización para reducir las palabras a su forma base antes del análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    if not isinstance(text, str):\n",
    "        return pd.Series([0, 0, 0, 0])\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    num_palabras = len(tokens)\n",
    "    tokens_lematizados = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    num_sospechosas = sum(1 for palabra in tokens if palabra in palabras_sospechosas)\n",
    "    sentimiento = analyzer.polarity_scores(text)['compound']\n",
    "    num_exclamaciones = text.count('!') + text.count('¡')\n",
    "    return pd.Series([num_palabras, num_sospechosas, sentimiento, num_exclamaciones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Titulo', 'Numero_Sospechosas_Titulo', 'Sentimiento_Titulo', 'Exclamaciones_Titulo']] = df['Titulo'].apply(lambda x: extract_text_features(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Titulo', 'Numero_Sospechosas_Titulo', 'Sentimiento_Titulo', 'Exclamaciones_Titulo']] = df['Titulo'].apply(lambda x: extract_text_features(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Titulo', 'Numero_Sospechosas_Titulo', 'Sentimiento_Titulo', 'Exclamaciones_Titulo']] = df['Titulo'].apply(lambda x: extract_text_features(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Titulo', 'Numero_Sospechosas_Titulo', 'Sentimiento_Titulo', 'Exclamaciones_Titulo']] = df['Titulo'].apply(lambda x: extract_text_features(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Descripcion', 'Numero_Sospechosas_Descripcion', 'Sentimiento_Descripcion', 'Exclamaciones_Descripcion']] = df['Descripcion'].apply(lambda x: extract_text_features(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Descripcion', 'Numero_Sospechosas_Descripcion', 'Sentimiento_Descripcion', 'Exclamaciones_Descripcion']] = df['Descripcion'].apply(lambda x: extract_text_features(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Descripcion', 'Numero_Sospechosas_Descripcion', 'Sentimiento_Descripcion', 'Exclamaciones_Descripcion']] = df['Descripcion'].apply(lambda x: extract_text_features(x))\n",
      "/var/folders/1j/z75cknhx76s2v56sd6b61_5w0000gn/T/ipykernel_2937/3815395875.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['Numero_Palabras_Descripcion', 'Numero_Sospechosas_Descripcion', 'Sentimiento_Descripcion', 'Exclamaciones_Descripcion']] = df['Descripcion'].apply(lambda x: extract_text_features(x))\n"
     ]
    }
   ],
   "source": [
    "df[['Numero_Palabras_Titulo', 'Numero_Sospechosas_Titulo', 'Sentimiento_Titulo', 'Exclamaciones_Titulo']] = df['Titulo'].apply(lambda x: extract_text_features(x))\n",
    "df[['Numero_Palabras_Descripcion', 'Numero_Sospechosas_Descripcion', 'Sentimiento_Descripcion', 'Exclamaciones_Descripcion']] = df['Descripcion'].apply(lambda x: extract_text_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Titulo_procesado</th>\n",
       "      <th>Descripcion_procesado</th>\n",
       "      <th>Numero_Palabras_Titulo</th>\n",
       "      <th>Numero_Sospechosas_Titulo</th>\n",
       "      <th>Sentimiento_Titulo</th>\n",
       "      <th>Exclamaciones_Titulo</th>\n",
       "      <th>Numero_Palabras_Descripcion</th>\n",
       "      <th>Numero_Sospechosas_Descripcion</th>\n",
       "      <th>Sentimiento_Descripcion</th>\n",
       "      <th>Exclamaciones_Descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>guardian va con sanchez necesita que su apuest...</td>\n",
       "      <td>el diario britanico publico este pasado jueves...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>revelan que el gobierno negocio la liberacion ...</td>\n",
       "      <td>revelan que el gobierno negocio la liberacion ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.8177</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>el o nunca de joan fuster sobre el estatuto va...</td>\n",
       "      <td>el valencianismo convoca en castello su fiesta...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>iglesias alienta a yolanda diaz erc y eh bildu...</td>\n",
       "      <td>en politica igual que hay que negociar con los...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>puigdemont seria ninguna tragedia una repetici...</td>\n",
       "      <td>en una entrevista en el punt avui el lider de ...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57058</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El Defensor del Pueblo reclama a la Comunidad ...</td>\n",
       "      <td>El gobierno regional han indicado que la atenc...</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>el defensor del pueblo reclama a la comunidad ...</td>\n",
       "      <td>el gobierno regional han indicado que la atenc...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57059</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>El EQUO plantea ceder la presidencia de la Com...</td>\n",
       "      <td>Si la higiene democrática nos lleva a esa exig...</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>el equo plantea ceder la presidencia de la com...</td>\n",
       "      <td>si la higiene democratica nos lleva a esa exig...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57060</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Alberto Garzón: 'Que los Borbones son unos lad...</td>\n",
       "      <td>El coordinador federal de IU asegura que la mo...</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>alberto garzon los borbones son unos ladrones ...</td>\n",
       "      <td>el coordinador federal de iu asegura que la mo...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57061</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Vox exige entrar en el Gobierno de Castilla y ...</td>\n",
       "      <td>Santiago Abascal: Vox tiene el derecho y el de...</td>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>vox exige entrar en el gobierno de castilla y ...</td>\n",
       "      <td>santiago abascal vox tiene el derecho y el deb...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57062</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Unas 300 personas protestan contra la visita d...</td>\n",
       "      <td>Los Mossos dEsquadra han blindado los alrededo...</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>unas three hundred personas protestan contra l...</td>\n",
       "      <td>los mossos desquadra han blindado los alrededo...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56613 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label                                             Titulo  \\\n",
       "0      ID      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1      ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2      ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3      ID      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4      ID      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "...    ..    ...                                                ...   \n",
       "57058  ID      1  El Defensor del Pueblo reclama a la Comunidad ...   \n",
       "57059  ID      0  El EQUO plantea ceder la presidencia de la Com...   \n",
       "57060  ID      1  Alberto Garzón: 'Que los Borbones son unos lad...   \n",
       "57061  ID      1  Vox exige entrar en el Gobierno de Castilla y ...   \n",
       "57062  ID      1  Unas 300 personas protestan contra la visita d...   \n",
       "\n",
       "                                             Descripcion      Fecha  \\\n",
       "0      El diario británico publicó este pasado jueves... 2023-06-02   \n",
       "1      REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ... 2023-10-01   \n",
       "2      El valencianismo convoca en Castelló su fiesta... 2022-04-25   \n",
       "3      En política, igual que hay que negociar con lo... 2022-01-03   \n",
       "4      En una entrevista en El Punt Avui, el líder de... 2018-03-09   \n",
       "...                                                  ...        ...   \n",
       "57058  El gobierno regional han indicado que la atenc... 2021-06-08   \n",
       "57059  Si la higiene democrática nos lleva a esa exig... 2020-09-08   \n",
       "57060  El coordinador federal de IU asegura que la mo... 2018-07-12   \n",
       "57061  Santiago Abascal: Vox tiene el derecho y el de... 2022-02-13   \n",
       "57062  Los Mossos dEsquadra han blindado los alrededo... 2020-10-09   \n",
       "\n",
       "                                        Titulo_procesado  \\\n",
       "0      guardian va con sanchez necesita que su apuest...   \n",
       "1      revelan que el gobierno negocio la liberacion ...   \n",
       "2      el o nunca de joan fuster sobre el estatuto va...   \n",
       "3      iglesias alienta a yolanda diaz erc y eh bildu...   \n",
       "4      puigdemont seria ninguna tragedia una repetici...   \n",
       "...                                                  ...   \n",
       "57058  el defensor del pueblo reclama a la comunidad ...   \n",
       "57059  el equo plantea ceder la presidencia de la com...   \n",
       "57060  alberto garzon los borbones son unos ladrones ...   \n",
       "57061  vox exige entrar en el gobierno de castilla y ...   \n",
       "57062  unas three hundred personas protestan contra l...   \n",
       "\n",
       "                                   Descripcion_procesado  \\\n",
       "0      el diario britanico publico este pasado jueves...   \n",
       "1      revelan que el gobierno negocio la liberacion ...   \n",
       "2      el valencianismo convoca en castello su fiesta...   \n",
       "3      en politica igual que hay que negociar con los...   \n",
       "4      en una entrevista en el punt avui el lider de ...   \n",
       "...                                                  ...   \n",
       "57058  el gobierno regional han indicado que la atenc...   \n",
       "57059  si la higiene democratica nos lleva a esa exig...   \n",
       "57060  el coordinador federal de iu asegura que la mo...   \n",
       "57061  santiago abascal vox tiene el derecho y el deb...   \n",
       "57062  los mossos desquadra han blindado los alrededo...   \n",
       "\n",
       "       Numero_Palabras_Titulo  Numero_Sospechosas_Titulo  Sentimiento_Titulo  \\\n",
       "0                        16.0                        0.0                 0.0   \n",
       "1                        18.0                        0.0                 0.0   \n",
       "2                        15.0                        0.0                 0.0   \n",
       "3                        20.0                        0.0                 0.0   \n",
       "4                        12.0                        1.0                 0.0   \n",
       "...                       ...                        ...                 ...   \n",
       "57058                    20.0                        0.0                 0.0   \n",
       "57059                    20.0                        0.0                 0.0   \n",
       "57060                    15.0                        0.0                 0.0   \n",
       "57061                    22.0                        0.0                 0.0   \n",
       "57062                    11.0                        0.0                 0.0   \n",
       "\n",
       "       Exclamaciones_Titulo  Numero_Palabras_Descripcion  \\\n",
       "0                       0.0                         37.0   \n",
       "1                       0.0                        595.0   \n",
       "2                       0.0                         32.0   \n",
       "3                       0.0                         23.0   \n",
       "4                       0.0                         47.0   \n",
       "...                     ...                          ...   \n",
       "57058                   0.0                         45.0   \n",
       "57059                   0.0                         54.0   \n",
       "57060                   0.0                         12.0   \n",
       "57061                   0.0                         48.0   \n",
       "57062                   0.0                         34.0   \n",
       "\n",
       "       Numero_Sospechosas_Descripcion  Sentimiento_Descripcion  \\\n",
       "0                                 0.0                   0.0000   \n",
       "1                                 3.0                  -0.8177   \n",
       "2                                 0.0                   0.4767   \n",
       "3                                 0.0                   0.3400   \n",
       "4                                 0.0                   0.3400   \n",
       "...                               ...                      ...   \n",
       "57058                             0.0                  -0.2960   \n",
       "57059                             0.0                  -0.2960   \n",
       "57060                             0.0                   0.0000   \n",
       "57061                             0.0                  -0.2960   \n",
       "57062                             0.0                   0.0000   \n",
       "\n",
       "       Exclamaciones_Descripcion  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "...                          ...  \n",
       "57058                        0.0  \n",
       "57059                        0.0  \n",
       "57060                        0.0  \n",
       "57061                        0.0  \n",
       "57062                        0.0  \n",
       "\n",
       "[56613 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticias Verdaderas (1): 32737\n",
      "Noticias Falsas (0): 23876\n",
      "Cantidad de diferencia: 8861\n"
     ]
    }
   ],
   "source": [
    "cantidadSi = (df[\"Label\"] == 1).sum()\n",
    "cantidadNo = (df[\"Label\"] == 0).sum()\n",
    "print(f\"Noticias Verdaderas (1): {cantidadSi}\")\n",
    "print(f\"Noticias Falsas (0): {cantidadNo}\")\n",
    "print(f\"Cantidad de diferencia: {cantidadSi-cantidadNo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que hay una gran cantidad de desbalance entre las noticias verdaderas y falsas con una diferencia de 9253 datos entonces construiremos primero el modelo sin SMOTE que es una tecnica para generar datos sinteticos y otra usando SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de regresion logistica sin SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf.fit_transform(df['Titulo'] + ' ' + df['Descripcion']).toarray()  # Original\n",
    "# X_tfidf = tfidf.fit_transform(df['Titulo_procesado'] + ' ' + df['Descripcion_procesado']).toarray() # Si es que lo hago con datos preprocesados\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf, columns=[f'tfidf_{i}' for i in range(X_tfidf.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df[['Numero_Palabras_Titulo', 'Numero_Sospechosas_Titulo', 'Sentimiento_Titulo', 'Exclamaciones_Titulo',\n",
    "                   'Numero_Palabras_Descripcion', 'Numero_Sospechosas_Descripcion', 'Sentimiento_Descripcion', 'Exclamaciones_Descripcion']],\n",
    "               X_tfidf_df], axis=1)\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de X: (57056, 1008)\n",
      "Tamaño de y: (56613,)\n",
      "Filas en df: 56613\n",
      "Valores nulos en X: 446544\n",
      "Valores nulos en y: 0\n"
     ]
    }
   ],
   "source": [
    "#ELIMINAR\n",
    "print(\"Tamaño de X:\", X.shape)\n",
    "print(\"Tamaño de y:\", y.shape)\n",
    "print(\"Filas en df:\", len(df))\n",
    "print(\"Valores nulos en X:\", X.isna().sum().sum())\n",
    "print(\"Valores nulos en y:\", y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de X: (57056, 1008)\n",
      "Tamaño de y: (56613,)\n",
      "Valores nulos en X: 446544\n",
      "Valores nulos en y: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de X:\", X.shape)\n",
    "print(\"Tamaño de y:\", y.shape)\n",
    "\n",
    "# Asegurarse de que no haya nulos en X o y\n",
    "print(\"Valores nulos en X:\", X.isna().sum().sum())\n",
    "print(\"Valores nulos en y:\", y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [57056, 56613]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2777\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2781\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2782\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [57056, 56613]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = LogisticRegression(max_iter=1000)\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precisión del modelo: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nReporte completo:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Falsa', 'Verdadera']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Falsa', 'Verdadera'], yticklabels=['Falsa', 'Verdadera'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPesos de las características numéricas:\")\n",
    "for feature, coef in zip(X.columns[:6], modelo.coef_[0][:6]):\n",
    "    print(f\"{feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de regresion logistica con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "smote = SMOTE(sampling_strategy=0.9, random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = LogisticRegression(max_iter=1000)\n",
    "modelo.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(X_test)\n",
    "print(f\"Precisión del modelo: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nReporte completo:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Falsa', 'Verdadera']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Falsa', 'Verdadera'], yticklabels=['Falsa', 'Verdadera'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPesos de las características numéricas:\")\n",
    "for feature, coef in zip(X.columns[:6], modelo.coef_[0][:6]):\n",
    "    print(f\"{feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ya que se evidencia que este modelo tiene una precision un poco mayor el SMOTE no cambia mucho ahora probaremos ajustando los hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Rango de valores para regularización\n",
    "    'penalty': ['l1', 'l2'],  # Tipos de regularización (l1 = Lasso, l2 = Ridge)\n",
    "    'max_iter': [1000, 2000]  # Más iteraciones si no converge\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_base = LogisticRegression(solver='liblinear')  # 'liblinear' funciona bien con l1 y l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # Validación cruzada de 5 pliegues\n",
    "    scoring='f1_weighted',  # Optimizar para F1-score ponderado\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=1  # Mostrar progreso\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor F1-score en validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo y hiperparámetros\n",
    "print(\"\\nMejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor F1-score en validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Usar el mejor modelo para predecir\n",
    "mejor_modelo = grid_search.best_estimator_\n",
    "y_pred = mejor_modelo.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "print(f\"\\nPrecisión del modelo: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nReporte completo:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Falsa', 'Verdadera']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Falsa', 'Verdadera'], yticklabels=['Falsa', 'Verdadera'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'C': [0.1, 1.0, 10.0], 'max_iter': [1000, 2000]}\n",
    "# grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='f1_weighted')\n",
    "# grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "# modelo = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df[\"combined_text\"] = df[\"Titulo\"].fillna(\"\") + \" \" + df[\"Descripcion\"].fillna(\"\")\n",
    "\n",
    "\n",
    "df[\"combined_text\"] = df[\"combined_text\"].apply(lambda x: re.sub(r'\\d+', '', x))  # Elimina números\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "vectorizacion = tfidf_vectorizer.fit_transform(df[\"combined_text\"].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = tfidf_vectorizer.get_feature_names_out()\n",
    "palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis desbalanceo de Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es dividir los datos en el set de prueba y el set de entrenemiento, ya que la tecnica de SMOTE para corregir el desbalanceo de hace sobre los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectorizacion,df[\"Label\"] , test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar SMOTE para corregir el desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y_train\n",
    "x=y_train\n",
    "\n",
    "count_class = y.value_counts() # Count the occurrences of each class\n",
    "count_class.index\n",
    "plt.bar(count_class.index, count_class.values)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class')\n",
    "plt.xticks(count_class.index, ['Class 1', 'Class 0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y_train_balanced\n",
    "x=y_train_balanced\n",
    "\n",
    "count_class = y.value_counts() # Count the occurrences of each class\n",
    "count_class.index\n",
    "plt.bar(count_class.index, count_class.values)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class')\n",
    "plt.xticks(count_class.index, ['Class 1', 'Class 0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RandomForestClassifier\n",
    "# Definir valores a probar\n",
    "\n",
    "\n",
    "random_forest_with_somote = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_with_somote.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_prediccion = random_forest_with_somote.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_prediccion)\n",
    "classification_rep = classification_report(y_test, y_prediccion)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo sin SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando con el parámetro class_weight con el valor balanced para que el modelo ajuste los pesos de la clase minoritaria y tenga más influencia en la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_without_somote = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "random_forest_without_somote.fit(X_train, y_train)\n",
    "\n",
    "y_prediccion = random_forest_without_somote.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_prediccion)\n",
    "classification_rep = classification_report(y_test, y_prediccion)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el uso de la tecnica SMOTE en este caso no funciona. Los cambios no son significativos y no se ven mejoras en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar overfitting de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en entrenamiento\n",
    "train_accuracy = random_forest_with_somote.score(X_train, y_train)\n",
    "\n",
    "# Evaluar en prueba\n",
    "test_accuracy = random_forest_with_somote.score(X_test, y_test)\n",
    "\n",
    "print(f\"🔹 Accuracy en Train: {train_accuracy:.4f}\")\n",
    "print(f\"🔹 Accuracy en Test: {test_accuracy:.4f}\")\n",
    "\n",
    "print(f\"🔹 Diferencia Train-Test: {train_accuracy - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en entrenamiento\n",
    "train_accuracy = random_forest_without_somote.score(X_train, y_train)\n",
    "\n",
    "# Evaluar en prueba\n",
    "test_accuracy = random_forest_without_somote.score(X_test, y_test)\n",
    "\n",
    "print(f\"🔹 Accuracy en Train: {train_accuracy:.4f}\")\n",
    "print(f\"🔹 Accuracy en Test: {test_accuracy:.4f}\")\n",
    "\n",
    "print(f\"🔹 Diferencia Train-Test: {train_accuracy - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el modelo con hiperparametros para aumentar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest1 = RandomForestClassifier(n_estimators=100, min_samples_split=40,  max_leaf_nodes=500, class_weight=\"balanced\", random_state=42)\n",
    "random_forest1.fit(X_train, y_train)\n",
    "#600\n",
    "y_prediccion = random_forest1.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_prediccion)\n",
    "classification_rep = classification_report(y_test, y_prediccion)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar overfitting del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en entrenamiento\n",
    "train_accuracy = random_forest1.score(X_train, y_train)\n",
    "\n",
    "# Evaluar en prueba\n",
    "test_accuracy = random_forest1.score(X_test, y_test)\n",
    "\n",
    "print(f\"🔹 Accuracy en Train: {train_accuracy:.4f}\")\n",
    "print(f\"🔹 Accuracy en Test: {test_accuracy:.4f}\")\n",
    "\n",
    "print(f\"🔹 Diferencia Train-Test: {train_accuracy - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que con el ajuste de hiperparámetros el overfitting del modelo se redujo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_prediccion)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=random_forest1.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Análizando la matriz de confusión se puede decir que el modelo identificó erroneamente 1047 noticias verdaderas como noticias falsas. Por otro lado, 454 noticias falsas no fueron identificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Exactitud} = \\frac{6124 + 9494}{17119} = 0.9123\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Presición} = \\frac{VP}{VP + FP} = \\frac{9494}{9494 + 1047} = 0.90\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tiene una precisión del 90%, lo que significa que de todas las noticias clasificadas como falsas, el 90% realmente lo son. Esto indica un alto nivel de confianza en las predicciones positivas del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Recall} = \\frac{VP}{VP + FN} = \\frac{9494}{9494 + 454} = 0.95\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo es capaz de identificar correctamente el 95% de las noticias falsas. Esto indica que solo el 5% de las noticias falsas no fueron detectadas, o sea, fueron clasificadas incorrectamente como verdaderas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = random_forest1.feature_importances_\n",
    "importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_importancia = pd.DataFrame({\n",
    "    'Palabra': palabras,\n",
    "    'Importancia': importancia\n",
    "})\n",
    "palabras_importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 30\n",
    "top_words = palabras_importancia.sort_values(by='Importancia', ascending=False).head(top_n)\n",
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se convierte el texto en vectores numéricos, capturando la importancia de cada palabra en el documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además se concatenan las columnas Titulo y Descripcion para aplicar TF-IDF sobre el texto completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorización TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limitar a 5000 términos más frecuentes\n",
    "X_tfidf = tfidf.fit_transform(df['Titulo'] + ' ' + df['Descripcion']).toarray()\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf, columns=[f'tfidf_{i}' for i in range(X_tfidf.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División datos entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se divide el conjunto de datos en entrenamiento (75%) y prueba (25%), se usa un kernel lineal (kernel='linear') porque es adecuado para problemas de texto y es más interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X = X_tfidf_df \n",
    "y = df['Label'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas de modelo sin SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_sin_smote = LinearSVC(random_state=42, dual=False)\n",
    "modelo_sin_smote.fit(X_train, y_train)\n",
    "y_pred_sin_smote = modelo_sin_smote.predict(X_test)\n",
    "print(\"Sin SMOTE:\")\n",
    "print(f\"Precisión: {accuracy_score(y_test, y_pred_sin_smote) * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred_sin_smote, target_names=['Falsa', 'Verdadera']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un pipeline con SMOTE y LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  # Aplicar SMOTE\n",
    "    ('svm', LinearSVC(random_state=42, dual=False))  # Modelo LinearSVC\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada k-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada (k-Fold) divide los datos en k=5 subconjuntos y evalúa el modelo en cada uno ,proporcionando una estimación más robusta del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Puntuaciones de validación cruzada:\", scores)\n",
    "print(\"Precisión promedio:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de hiperparámetros con el pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV realiza una búsqueda exhaustiva sobre una grilla de hiperparámetros para encontrar los mejores valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se evalúa con validación cruzada (cv=5) y se selecciona la combinación de hiperparámetros que maximiza la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'svm__C': [0.1, 1.0, 10.0],# Valores de C para LinearSVC\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"\\nMejores hiperparámetros:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1.0 es el mejor, esto nos indica que el modelo no necesita ser muy flexible (C=10.0) ni muy rígido (C=0.1) para lograr un buen rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_modelo = grid_search.best_estimator_\n",
    "y_pred = mejor_modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV realiza una búsqueda exhaustiva sobre una grilla de hiperparámetros para encontrar los mejores valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se evalúa con validación cruzada (cv=5) y se selecciona la combinación de hiperparámetros que maximiza la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nPrecisión del modelo SVM con SMOTE: {precision * 100:.2f}%\")\n",
    "print(\"\\nReporte completo:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Falsa', 'Verdadera']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Falsa', 'Verdadera'], yticklabels=['Falsa', 'Verdadera'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión - SVM con SMOTE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
